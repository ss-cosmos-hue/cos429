{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce2e9972",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef096527",
   "metadata": {},
   "source": [
    "# Part 2: Classic recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9068aeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import get_CIFAR10_data, train, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e219a93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (4500, 32, 32, 3)\n",
      "Train labels shape:  (4500,)\n",
      "Validation data shape:  (500, 32, 32, 3)\n",
      "Validation labels shape:  (500,)\n",
      "Test data shape:  (1000, 32, 32, 3)\n",
      "Test labels shape:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "meta = pickle.load(open('data/cifar-10-batches-py/batches.meta', 'rb'), encoding='bytes')\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data(cifar10_dir='data/cifar-10-batches-py',\n",
    "                                                                  num_training=4500, \n",
    "                                                                  num_validation=500, \n",
    "                                                                  num_test=1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "676e481d",
   "metadata": {},
   "source": [
    "## Question 2. Color features (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "675cbc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (4500, 32, 32, 3)\n",
      "Train labels shape:  (4500,)\n",
      "Validation data shape:  (500, 32, 32, 3)\n",
      "Validation labels shape:  (500,)\n",
      "Test data shape:  (1000, 32, 32, 3)\n",
      "Test labels shape:  (1000,)\n",
      "reg 1.000000e-01 train accuracy: 0.132444 val accuracy: 0.144000\n",
      "\n",
      "best validation accuracy achieved during training: 0.144000\n",
      "\n",
      "final test set accuracy: 0.134000\n"
     ]
    }
   ],
   "source": [
    "# ALL OPERATIONS\n",
    "from assn2 import load_average_color_with_bias\n",
    "\n",
    "regularization_strength = [0.09, 0.10, 0.11]\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data(cifar10_dir='data/cifar-10-batches-py',\n",
    "                                                                  num_training=4500, \n",
    "                                                                  num_validation=500, \n",
    "                                                                  num_test=1000)\n",
    "X_train = load_average_color_with_bias(X_train)\n",
    "X_val = load_average_color_with_bias(X_val)\n",
    "X_test = load_average_color_with_bias(X_test)\n",
    "best_color = train(X_train, y_train, X_val, y_val, X_test, y_test, regularization_strength)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff4348fa",
   "metadata": {},
   "source": [
    "## Question 3. Bag of SIFT features (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbd518d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (4500, 32, 32, 3)\n",
      "Train labels shape:  (4500,)\n",
      "Validation data shape:  (500, 32, 32, 3)\n",
      "Validation labels shape:  (500,)\n",
      "Test data shape:  (1000, 32, 32, 3)\n",
      "Test labels shape:  (1000,)\n",
      "reg 1.000000e+03 train accuracy: 0.237556 val accuracy: 0.246000\n",
      "\n",
      "best validation accuracy achieved during training: 0.246000\n",
      "final test set accuracy: 0.232000\n"
     ]
    }
   ],
   "source": [
    "from features import extract_sift_for_dataset\n",
    "from assn2 import load_flatten\n",
    "from assn2 import load_histogram_with_bias\n",
    "from kmeans import kmeans\n",
    "\n",
    "step_size = 4\n",
    "K = 16\n",
    "niter = 4\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data(cifar10_dir='data/cifar-10-batches-py',\n",
    "                                                                  num_training=4500, \n",
    "                                                                  num_validation=500, \n",
    "                                                                  num_test=1000)\n",
    "X_train_features = extract_sift_for_dataset(X_train, step_size=step_size)\n",
    "X_val_features = extract_sift_for_dataset(X_val, step_size=step_size)\n",
    "X_test_features = extract_sift_for_dataset(X_test, step_size=step_size)\n",
    "X_train_features_flattened = load_flatten(X_train_features)\n",
    "labels_train, centroids = kmeans(X_train_features_flattened, K, niter)\n",
    "train_hist = load_histogram_with_bias(X_train_features, centroids)\n",
    "val_hist = load_histogram_with_bias(X_val_features, centroids)\n",
    "test_hist = load_histogram_with_bias(X_test_features, centroids)\n",
    "regularization_strengths = [1e3]\n",
    "best_color = train(train_hist, y_train, val_hist, y_val, test_hist, y_test, regularization_strengths, skip_test=True)\n",
    "evaluate(best_color, test_hist, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a59568",
   "metadata": {},
   "source": [
    "## Question 4. SPM representation (15 points)\n",
    "\n",
    "Above, we selected feature points in uniform-distanced pixels.\n",
    "One drawback of the bag-of-words approach is that it discards spatial information. \n",
    "\n",
    "Hence, we will now try encoding spatial information using Spatial Pyramid Matching (SPM) proposed in Lazebnik et al. 2006. At a high level, SPM works by breaking up an image into different regions and computing the SIFT descriptor at each region, forming a histogram of visual words in each region, and then concatenatating them into a single 1D vector representation.\n",
    "\n",
    "**Do this**: Construct a SPM representation of the images and train a classifier. Specifically, implement `spatial_pyramid_matching_with_bias()` in `features.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9be9927c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (4500, 32, 32, 3)\n",
      "Train labels shape:  (4500,)\n",
      "Validation data shape:  (500, 32, 32, 3)\n",
      "Validation labels shape:  (500,)\n",
      "Test data shape:  (1000, 32, 32, 3)\n",
      "Test labels shape:  (1000,)\n",
      "reg 1.000000e+03 train accuracy: 0.286444 val accuracy: 0.272000\n",
      "reg 3.000000e+03 train accuracy: 0.278444 val accuracy: 0.268000\n",
      "reg 5.000000e+03 train accuracy: 0.259333 val accuracy: 0.266000\n",
      "reg 7.000000e+03 train accuracy: 0.250889 val accuracy: 0.238000\n",
      "reg 1.000000e+04 train accuracy: 0.260444 val accuracy: 0.266000\n",
      "reg 3.000000e+04 train accuracy: 0.217333 val accuracy: 0.220000\n",
      "\n",
      "best validation accuracy achieved during training: 0.272000\n",
      "final test set accuracy: 0.271000\n"
     ]
    }
   ],
   "source": [
    "from features import spatial_pyramid_matching_with_bias\n",
    "\n",
    "L = 2\n",
    "K = 16\n",
    "niter = 4\n",
    "regularization_strengths = [1e3]\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data(cifar10_dir='data/cifar-10-batches-py',\n",
    "                                                                  num_training=4500, \n",
    "                                                                  num_validation=500, \n",
    "                                                                  num_test=1000)\n",
    "X_train_features = extract_sift_for_dataset(X_train, step_size=1)\n",
    "X_train_features_flattened = load_flatten(X_train_features)\n",
    "X_val_features = extract_sift_for_dataset(X_val, step_size=1)\n",
    "X_test_features = extract_sift_for_dataset(X_test, step_size=1)\n",
    "_, centroids = kmeans(X_train_features_flattened, K, niter)\n",
    "X_train_spm = [spatial_pyramid_matching_with_bias(L, \n",
    "                                        X_train_features[i].reshape((32, 32, 128)), \n",
    "                                        centroids) \n",
    "            for i in range(len(X_train))]\n",
    "X_val_spm = [spatial_pyramid_matching_with_bias(L,\n",
    "                                      X_val_features[i].reshape((32, 32, 128)), \n",
    "                                      centroids) \n",
    "            for i in range(len(X_val))]\n",
    "X_test_spm = [spatial_pyramid_matching_with_bias(L,\n",
    "                                       X_test_features[i].reshape((32, 32, 128)),\n",
    "                                       centroids)  \n",
    "              for i in range(len(X_test))]\n",
    "X_train_spm = np.stack(X_train_spm, 0)\n",
    "X_val_spm = np.stack(X_val_spm, 0)\n",
    "X_test_spm = np.stack(X_test_spm, 0)\n",
    "best_color = train(X_train_spm, y_train, X_val_spm, y_val, X_test_spm, y_test, regularization_strengths, skip_test=True)\n",
    "evaluate(best_color, X_test_spm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44a8466",
   "metadata": {},
   "source": [
    "## Question 5. Histogram of Oriented Gradients (10 points)\n",
    "\n",
    "Rather than extracting local SIFT features, we can compute a global histogram of oriented gradients (HOG) image descriptor. \n",
    "\n",
    "**Do this**: Implement `get_differential_filter()` and `filter_image()` in `features.py`, and `load_hog_representation_with_bias()` in `assn2.py`. Then compute HOG descriptors and train a classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "affdd35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (4500, 32, 32, 3)\n",
      "Train labels shape:  (4500,)\n",
      "Validation data shape:  (500, 32, 32, 3)\n",
      "Validation labels shape:  (500,)\n",
      "Test data shape:  (1000, 32, 32, 3)\n",
      "Test labels shape:  (1000,)\n",
      "reg 1.000000e+03 train accuracy: 0.122889 val accuracy: 0.094000\n",
      "reg 3.000000e+03 train accuracy: 0.105556 val accuracy: 0.088000\n",
      "reg 5.000000e+03 train accuracy: 0.105556 val accuracy: 0.088000\n",
      "reg 7.000000e+03 train accuracy: 0.203556 val accuracy: 0.144000\n",
      "reg 1.000000e+04 train accuracy: 0.104444 val accuracy: 0.104000\n",
      "reg 3.000000e+04 train accuracy: 0.148000 val accuracy: 0.154000\n",
      "\n",
      "best validation accuracy achieved during training: 0.154000\n",
      "\n",
      "final test set accuracy: 0.158000\n"
     ]
    }
   ],
   "source": [
    "from assn2 import load_hog_representation_with_bias\n",
    "\n",
    "cell_size = 2\n",
    "block_size = 2\n",
    "regularization_strengths = [1e3,3e3,5e3,7e3,1e4,3e4]\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data(cifar10_dir='data/cifar-10-batches-py',\n",
    "                                                                  num_training=4500, \n",
    "                                                                  num_validation=500, \n",
    "                                                                  num_test=1000)\n",
    "X_train_hog =  load_hog_representation_with_bias(X_train, cell_size, block_size)\n",
    "X_val_hog = load_hog_representation_with_bias(X_val, cell_size, block_size)\n",
    "X_test_hog = load_hog_representation_with_bias(X_test, cell_size, block_size)\n",
    "best_color = train(X_train_hog, y_train, X_val_hog, y_val, X_test_hog, y_test, regularization_strengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e999d961",
   "metadata": {},
   "source": [
    "## Question 6. Pixels (5 points)\n",
    "\n",
    "Finally, let's use the pixels themselves to train a classifier. That is, just reshape a 32x32x3 image into a 32x32x3=3072 vector.\n",
    "\n",
    "**Do this:** Process the images and train a classifier. Specifically, implement `load_vector_image_with_bias()` in `assn2.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f7b0d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (4500, 32, 32, 3)\n",
      "Train labels shape:  (4500,)\n",
      "Validation data shape:  (500, 32, 32, 3)\n",
      "Validation labels shape:  (500,)\n",
      "Test data shape:  (1000, 32, 32, 3)\n",
      "Test labels shape:  (1000,)\n",
      "reg 1.000000e+03 train accuracy: 0.257778 val accuracy: 0.242000\n",
      "reg 3.000000e+03 train accuracy: 0.209111 val accuracy: 0.186000\n",
      "reg 5.000000e+03 train accuracy: 0.108000 val accuracy: 0.090000\n",
      "reg 7.000000e+03 train accuracy: 0.120000 val accuracy: 0.100000\n",
      "reg 1.000000e+04 train accuracy: 0.144444 val accuracy: 0.120000\n",
      "reg 3.000000e+04 train accuracy: 0.097778 val accuracy: 0.092000\n",
      "\n",
      "best validation accuracy achieved during training: 0.242000\n",
      "\n",
      "final test set accuracy: 0.207000\n"
     ]
    }
   ],
   "source": [
    "from assn2 import load_vector_image_with_bias\n",
    "\n",
    "regularization_strengths = [1e3,3e3,5e3,7e3,1e4,3e4]\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data(cifar10_dir='data/cifar-10-batches-py',\n",
    "                                                                  num_training=4500, \n",
    "                                                                  num_validation=500, \n",
    "                                                                  num_test=1000)\n",
    "X_train, X_val, X_test = load_vector_image_with_bias(X_train, X_val, X_test)\n",
    "best_color = train(X_train, y_train, X_val, y_val, X_test, y_test, regularization_strengths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cos429",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "000aad7aade412d5ec44f41a60524792b2a1feedd24187e4b19c8dff80ec5173"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
