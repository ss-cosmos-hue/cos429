{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"dataset-resized.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"trashnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "f3_3Xk8_SW_c"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet34,ResNet34_Weights\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "mhdPpxn-SeRf"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img = Image.open(\"trashnet/dataset-resized/plastic/plastic1.jpg\")\n",
    "sample_img_arr = np.array(sample_img)\n",
    "H,W,_ = np.shape(sample_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"cardboard\",\"glass\",\"metal\",\"paper\",\"plastic\",\"trash\"]\n",
    "class_sizes = {\"cardboard\":403,\"glass\":501,\"metal\":410,\"paper\":594,\"plastic\":482,\"trash\":137}\n",
    "class_nums =  {\"cardboard\":0,\"glass\":1,\"metal\":2,\"paper\":3,\"plastic\":4,\"trash\":5}\n",
    "\n",
    "#n_whole = np.sum(list(class_sizes.values()))\n",
    "n_whole = 30*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((n_whole,H,W,3))\n",
    "y = np.zeros((n_whole))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_count = 0\n",
      "total_count = 100\n"
     ]
    }
   ],
   "source": [
    "#update X and y\n",
    "total_count  = 0\n",
    "for categ in classes:\n",
    "    n_elem = class_sizes[categ]\n",
    "    n_elem = 30\n",
    "    for i in range(1,1+n_elem):\n",
    "        if total_count%100 == 0:\n",
    "            print(f'total_count = {total_count}')\n",
    "        X[total_count] = np.array(Image.open(f'trashnet/dataset-resized/{categ}/{categ}{i}.jpg'))\n",
    "        y[total_count] = class_nums[categ]\n",
    "        total_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((n_whole,3,H,W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,test_X,train_y,test_y = train_test_split(X, y, test_size=15, random_state=42)\n",
    "val_X,test_X ,val_y,test_y = train_test_split(test_X, test_y, test_size=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = torch.FloatTensor(train_X)\n",
    "train_y = torch.LongTensor(train_y)\n",
    "train_dataset = torch.utils.data.TensorDataset(train_X, train_y)\n",
    "trainloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "#not sure we would uuse validationloader or testloader\n",
    "val_X = torch.FloatTensor(val_X)\n",
    "val_y = torch.LongTensor(val_y)\n",
    "val_dataset = torch.utils.data.TensorDataset(val_X, val_y)\n",
    "valloader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "test_X = torch.FloatTensor(test_X)\n",
    "test_y = torch.LongTensor(test_y)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_X, test_y)\n",
    "testloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train':trainloader,'val':valloader,'test':testloader}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet34()\n",
    "model.load_state_dict(torch.load(\"model_weights.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "DmipUJJPTIhy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " first layer: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n"
     ]
    }
   ],
   "source": [
    "first_layer = list(model.children())[0]\n",
    "print(f' first layer: {first_layer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "wFHrGk7c4nXR",
    "outputId": "01dd6d68-3090-400f-afb9-16973cc0ae3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 192, 256]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 192, 256]             128\n",
      "              ReLU-3         [-1, 64, 192, 256]               0\n",
      "         MaxPool2d-4          [-1, 64, 96, 128]               0\n",
      "            Conv2d-5          [-1, 64, 96, 128]          36,864\n",
      "       BatchNorm2d-6          [-1, 64, 96, 128]             128\n",
      "              ReLU-7          [-1, 64, 96, 128]               0\n",
      "            Conv2d-8          [-1, 64, 96, 128]          36,864\n",
      "       BatchNorm2d-9          [-1, 64, 96, 128]             128\n",
      "             ReLU-10          [-1, 64, 96, 128]               0\n",
      "       BasicBlock-11          [-1, 64, 96, 128]               0\n",
      "           Conv2d-12          [-1, 64, 96, 128]          36,864\n",
      "      BatchNorm2d-13          [-1, 64, 96, 128]             128\n",
      "             ReLU-14          [-1, 64, 96, 128]               0\n",
      "           Conv2d-15          [-1, 64, 96, 128]          36,864\n",
      "      BatchNorm2d-16          [-1, 64, 96, 128]             128\n",
      "             ReLU-17          [-1, 64, 96, 128]               0\n",
      "       BasicBlock-18          [-1, 64, 96, 128]               0\n",
      "           Conv2d-19          [-1, 64, 96, 128]          36,864\n",
      "      BatchNorm2d-20          [-1, 64, 96, 128]             128\n",
      "             ReLU-21          [-1, 64, 96, 128]               0\n",
      "           Conv2d-22          [-1, 64, 96, 128]          36,864\n",
      "      BatchNorm2d-23          [-1, 64, 96, 128]             128\n",
      "             ReLU-24          [-1, 64, 96, 128]               0\n",
      "       BasicBlock-25          [-1, 64, 96, 128]               0\n",
      "           Conv2d-26          [-1, 128, 48, 64]          73,728\n",
      "      BatchNorm2d-27          [-1, 128, 48, 64]             256\n",
      "             ReLU-28          [-1, 128, 48, 64]               0\n",
      "           Conv2d-29          [-1, 128, 48, 64]         147,456\n",
      "      BatchNorm2d-30          [-1, 128, 48, 64]             256\n",
      "           Conv2d-31          [-1, 128, 48, 64]           8,192\n",
      "      BatchNorm2d-32          [-1, 128, 48, 64]             256\n",
      "             ReLU-33          [-1, 128, 48, 64]               0\n",
      "       BasicBlock-34          [-1, 128, 48, 64]               0\n",
      "           Conv2d-35          [-1, 128, 48, 64]         147,456\n",
      "      BatchNorm2d-36          [-1, 128, 48, 64]             256\n",
      "             ReLU-37          [-1, 128, 48, 64]               0\n",
      "           Conv2d-38          [-1, 128, 48, 64]         147,456\n",
      "      BatchNorm2d-39          [-1, 128, 48, 64]             256\n",
      "             ReLU-40          [-1, 128, 48, 64]               0\n",
      "       BasicBlock-41          [-1, 128, 48, 64]               0\n",
      "           Conv2d-42          [-1, 128, 48, 64]         147,456\n",
      "      BatchNorm2d-43          [-1, 128, 48, 64]             256\n",
      "             ReLU-44          [-1, 128, 48, 64]               0\n",
      "           Conv2d-45          [-1, 128, 48, 64]         147,456\n",
      "      BatchNorm2d-46          [-1, 128, 48, 64]             256\n",
      "             ReLU-47          [-1, 128, 48, 64]               0\n",
      "       BasicBlock-48          [-1, 128, 48, 64]               0\n",
      "           Conv2d-49          [-1, 128, 48, 64]         147,456\n",
      "      BatchNorm2d-50          [-1, 128, 48, 64]             256\n",
      "             ReLU-51          [-1, 128, 48, 64]               0\n",
      "           Conv2d-52          [-1, 128, 48, 64]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 48, 64]             256\n",
      "             ReLU-54          [-1, 128, 48, 64]               0\n",
      "       BasicBlock-55          [-1, 128, 48, 64]               0\n",
      "           Conv2d-56          [-1, 256, 24, 32]         294,912\n",
      "      BatchNorm2d-57          [-1, 256, 24, 32]             512\n",
      "             ReLU-58          [-1, 256, 24, 32]               0\n",
      "           Conv2d-59          [-1, 256, 24, 32]         589,824\n",
      "      BatchNorm2d-60          [-1, 256, 24, 32]             512\n",
      "           Conv2d-61          [-1, 256, 24, 32]          32,768\n",
      "      BatchNorm2d-62          [-1, 256, 24, 32]             512\n",
      "             ReLU-63          [-1, 256, 24, 32]               0\n",
      "       BasicBlock-64          [-1, 256, 24, 32]               0\n",
      "           Conv2d-65          [-1, 256, 24, 32]         589,824\n",
      "      BatchNorm2d-66          [-1, 256, 24, 32]             512\n",
      "             ReLU-67          [-1, 256, 24, 32]               0\n",
      "           Conv2d-68          [-1, 256, 24, 32]         589,824\n",
      "      BatchNorm2d-69          [-1, 256, 24, 32]             512\n",
      "             ReLU-70          [-1, 256, 24, 32]               0\n",
      "       BasicBlock-71          [-1, 256, 24, 32]               0\n",
      "           Conv2d-72          [-1, 256, 24, 32]         589,824\n",
      "      BatchNorm2d-73          [-1, 256, 24, 32]             512\n",
      "             ReLU-74          [-1, 256, 24, 32]               0\n",
      "           Conv2d-75          [-1, 256, 24, 32]         589,824\n",
      "      BatchNorm2d-76          [-1, 256, 24, 32]             512\n",
      "             ReLU-77          [-1, 256, 24, 32]               0\n",
      "       BasicBlock-78          [-1, 256, 24, 32]               0\n",
      "           Conv2d-79          [-1, 256, 24, 32]         589,824\n",
      "      BatchNorm2d-80          [-1, 256, 24, 32]             512\n",
      "             ReLU-81          [-1, 256, 24, 32]               0\n",
      "           Conv2d-82          [-1, 256, 24, 32]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 24, 32]             512\n",
      "             ReLU-84          [-1, 256, 24, 32]               0\n",
      "       BasicBlock-85          [-1, 256, 24, 32]               0\n",
      "           Conv2d-86          [-1, 256, 24, 32]         589,824\n",
      "      BatchNorm2d-87          [-1, 256, 24, 32]             512\n",
      "             ReLU-88          [-1, 256, 24, 32]               0\n",
      "           Conv2d-89          [-1, 256, 24, 32]         589,824\n",
      "      BatchNorm2d-90          [-1, 256, 24, 32]             512\n",
      "             ReLU-91          [-1, 256, 24, 32]               0\n",
      "       BasicBlock-92          [-1, 256, 24, 32]               0\n",
      "           Conv2d-93          [-1, 256, 24, 32]         589,824\n",
      "      BatchNorm2d-94          [-1, 256, 24, 32]             512\n",
      "             ReLU-95          [-1, 256, 24, 32]               0\n",
      "           Conv2d-96          [-1, 256, 24, 32]         589,824\n",
      "      BatchNorm2d-97          [-1, 256, 24, 32]             512\n",
      "             ReLU-98          [-1, 256, 24, 32]               0\n",
      "       BasicBlock-99          [-1, 256, 24, 32]               0\n",
      "          Conv2d-100          [-1, 512, 12, 16]       1,179,648\n",
      "     BatchNorm2d-101          [-1, 512, 12, 16]           1,024\n",
      "            ReLU-102          [-1, 512, 12, 16]               0\n",
      "          Conv2d-103          [-1, 512, 12, 16]       2,359,296\n",
      "     BatchNorm2d-104          [-1, 512, 12, 16]           1,024\n",
      "          Conv2d-105          [-1, 512, 12, 16]         131,072\n",
      "     BatchNorm2d-106          [-1, 512, 12, 16]           1,024\n",
      "            ReLU-107          [-1, 512, 12, 16]               0\n",
      "      BasicBlock-108          [-1, 512, 12, 16]               0\n",
      "          Conv2d-109          [-1, 512, 12, 16]       2,359,296\n",
      "     BatchNorm2d-110          [-1, 512, 12, 16]           1,024\n",
      "            ReLU-111          [-1, 512, 12, 16]               0\n",
      "          Conv2d-112          [-1, 512, 12, 16]       2,359,296\n",
      "     BatchNorm2d-113          [-1, 512, 12, 16]           1,024\n",
      "            ReLU-114          [-1, 512, 12, 16]               0\n",
      "      BasicBlock-115          [-1, 512, 12, 16]               0\n",
      "          Conv2d-116          [-1, 512, 12, 16]       2,359,296\n",
      "     BatchNorm2d-117          [-1, 512, 12, 16]           1,024\n",
      "            ReLU-118          [-1, 512, 12, 16]               0\n",
      "          Conv2d-119          [-1, 512, 12, 16]       2,359,296\n",
      "     BatchNorm2d-120          [-1, 512, 12, 16]           1,024\n",
      "            ReLU-121          [-1, 512, 12, 16]               0\n",
      "      BasicBlock-122          [-1, 512, 12, 16]               0\n",
      "AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0\n",
      "          Linear-124                    [-1, 6]           3,078\n",
      "================================================================\n",
      "Total params: 21,287,750\n",
      "Trainable params: 21,287,750\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2.25\n",
      "Forward/backward pass size (MB): 377.25\n",
      "Params size (MB): 81.21\n",
      "Estimated Total Size (MB): 460.71\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 6)\n",
    "\n",
    "model = model.to(device)\n",
    "summary(model,(3,H,W))\n",
    "# 512 x 384 x 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "dcMkamhY4aTO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "except last layer: Linear(in_features=512, out_features=6, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# freeze all layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "last_layer = list(model.children())[-1]\n",
    "print(f'except last layer: {last_layer}')\n",
    "for param in last_layer.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "zQtZ4lPVVJ-d"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,     4] loss: 0.143 accuracy: 0.5405405163764954\n",
      "[10,     4] loss: 0.151 accuracy: 0.4864864945411682\n",
      "[15,     4] loss: 0.155 accuracy: 0.4324324429035187\n",
      "[20,     4] loss: 0.148 accuracy: 0.5405405163764954\n",
      "[25,     4] loss: 0.157 accuracy: 0.4324324429035187\n",
      "[30,     4] loss: 0.148 accuracy: 0.5405405163764954\n",
      "[35,     4] loss: 0.158 accuracy: 0.37837839126586914\n",
      "[40,     4] loss: 0.149 accuracy: 0.5135135054588318\n",
      "[45,     4] loss: 0.153 accuracy: 0.4324324429035187\n",
      "[50,     4] loss: 0.160 accuracy: 0.4054054021835327\n",
      "[55,     4] loss: 0.156 accuracy: 0.45945945382118225\n",
      "[60,     4] loss: 0.161 accuracy: 0.37837839126586914\n",
      "[65,     4] loss: 0.156 accuracy: 0.4864864945411682\n",
      "[70,     4] loss: 0.157 accuracy: 0.4054054021835327\n",
      "[75,     4] loss: 0.162 accuracy: 0.3243243098258972\n",
      "[80,     4] loss: 0.157 accuracy: 0.4324324429035187\n",
      "[85,     4] loss: 0.153 accuracy: 0.3513513505458832\n",
      "[90,     4] loss: 0.149 accuracy: 0.5135135054588318\n",
      "[95,     4] loss: 0.154 accuracy: 0.45945945382118225\n",
      "[100,     4] loss: 0.159 accuracy: 0.4054054021835327\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "outputs = None\n",
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    i = 0\n",
    "    for inputs, labels in dataloaders['train']:\n",
    "        # print(i)\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer_ft.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        # print(inputs[0]) \n",
    "        # print(inputs.dtype)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_ft.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        score = torch.mean((torch.Tensor.argmax(outputs,axis = 1)==labels).type(torch.FloatTensor))\n",
    "        i += 1\n",
    "    if epoch % 5 == 4:    # print every 2000 mini-batches\n",
    "        print(f'[{epoch + 1}, {i + 1:5d}] loss: {loss.item() / 10:.3f} accuracy: {score}')\n",
    "        running_loss = 0.0\n",
    "    exp_lr_scheduler.step()\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4zd7P8VDIgJ",
    "outputId": "31c731c0-e561-4d08-f982-0b4b811f29bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39.65176098, 47.01226751, 31.89552829, 38.14800158, 32.44954491,\n",
       "       10.84289672])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr = np.array([501,594,403,482,410,137])\n",
    "200*arr/np.sum(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "UMvCP2vtDTbB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "iw [~/.conda/envs/iw/]",
   "language": "python",
   "name": "conda_iw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
