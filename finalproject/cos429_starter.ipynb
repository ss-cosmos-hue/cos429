{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"dataset-resized.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"trashnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "f3_3Xk8_SW_c"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet34,ResNet34_Weights\n",
    "import torch.nn as nn\n",
    "import torch \n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img = Image.open(\"trashnet/dataset-resized/plastic/plastic1.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mhdPpxn-SeRf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img = plt.imread(\"trashnet/dataset-resized/plastic/plastic1.jpg\")\n",
    "H,W,_ = np.shape(sample_img)\n",
    "\n",
    "classes = [\"cardboard\",\"glass\",\"metal\",\"paper\",\"plastic\",\"trash\"]\n",
    "class_sizes = {\"cardboard\":403,\"glass\":501,\"metal\":410,\"paper\":594,\"plastic\":482,\"trash\":137}\n",
    "class_nums =  {\"cardboard\":0,\"glass\":1,\"metal\":2,\"paper\":3,\"plastic\":4,\"trash\":5}\n",
    "\n",
    "n_whole = np.sum(list(class_sizes.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = ResNet34_Weights.DEFAULT.transforms().mean\n",
    "std = ResNet34_Weights.DEFAULT.transforms().std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_count = 0\n",
      "total_count = 100\n",
      "total_count = 200\n",
      "total_count = 300\n",
      "total_count = 400\n",
      "total_count = 500\n",
      "total_count = 600\n",
      "total_count = 700\n",
      "total_count = 800\n",
      "total_count = 900\n",
      "total_count = 1000\n",
      "total_count = 1100\n",
      "total_count = 1200\n",
      "total_count = 1300\n",
      "total_count = 1400\n",
      "total_count = 1500\n",
      "total_count = 1600\n",
      "total_count = 1700\n",
      "total_count = 1800\n",
      "total_count = 1900\n",
      "total_count = 2000\n",
      "total_count = 2100\n",
      "total_count = 2200\n",
      "total_count = 2300\n",
      "total_count = 2400\n",
      "total_count = 2500\n",
      "store in X and y\n"
     ]
    }
   ],
   "source": [
    "# def gen_dataset():\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "#update X and y\n",
    "total_count  = 0\n",
    "for categ in classes:\n",
    "    n_elem = class_sizes[categ]\n",
    "    for i in range(1,1+n_elem):\n",
    "        if total_count%100 == 0:\n",
    "            print(f'total_count = {total_count}')\n",
    "        # X[total_count] = np.array(Image.open(f'trashnet/dataset-resized/{categ}/{categ}{i}.jpg'))\n",
    "        image = np.copy(plt.imread(f'trashnet/dataset-resized/{categ}/{categ}{i}.jpg'))\n",
    "        for i in range(len(image)):\n",
    "            image[i]=image[i]-mean\n",
    "            image[i]=image[i]/std\n",
    "        X.append(image)\n",
    "        y.append(class_nums[categ])\n",
    "        total_count += 1\n",
    "print(\"store in X and y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split\n",
      "dataloader train\n"
     ]
    }
   ],
   "source": [
    "X = X.reshape((n_whole,3,H,W))\n",
    "print(\"split\")\n",
    "train_X,test_X,train_y,test_y = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "val_X,test_X ,val_y,test_y = train_test_split(test_X, test_y, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"dataloader train\")\n",
    "train_X = torch.FloatTensor(train_X)\n",
    "train_y = torch.LongTensor(train_y)\n",
    "train_dataset = torch.utils.data.TensorDataset(train_X, train_y)\n",
    "del train_X\n",
    "del train_y\n",
    "gc.collect()\n",
    "trainloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation\n"
     ]
    }
   ],
   "source": [
    "#not sure we would uuse validationloader or testloader\n",
    "print(\"validation\")\n",
    "val_X = torch.FloatTensor(val_X)\n",
    "val_y = torch.LongTensor(val_y)\n",
    "val_dataset = torch.utils.data.TensorDataset(val_X, val_y)\n",
    "del val_X\n",
    "del val_y\n",
    "gc.collect()\n",
    "valloader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=64, shuffle=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")\n",
    "test_X = torch.FloatTensor(test_X)\n",
    "test_y = torch.LongTensor(test_y)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_X, test_y)\n",
    "del test_X\n",
    "del test_y\n",
    "gc.collect()\n",
    "testloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=True, num_workers=1)\n",
    "\n",
    "dataloaders = {'train':trainloader,'val':valloader,'test':testloader}\n",
    "\n",
    "## model initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " first layer: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "except last layer: Linear(in_features=512, out_features=6, bias=True)\n"
     ]
    }
   ],
   "source": [
    "model = resnet34()\n",
    "model.load_state_dict(torch.load(\"model_weights.pth\"))\n",
    "\n",
    "first_layer = list(model.children())[0]\n",
    "print(f' first layer: {first_layer}')\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 6)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "#summary(model,(3,H,W))\n",
    "# 512 x 384 x 3\n",
    "\n",
    "# freeze all layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "last_layer = list(model.children())[-1]\n",
    "print(f'except last layer: {last_layer}')\n",
    "for param in last_layer.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    25] loss: 0.176 accuracy: 0.2954545319080353\n",
      "[2,    25] loss: 0.152 accuracy: 0.47727271914482117\n",
      "[3,    25] loss: 0.164 accuracy: 0.34090909361839294\n",
      "[4,    25] loss: 0.129 accuracy: 0.5909090638160706\n",
      "[5,    25] loss: 0.124 accuracy: 0.4545454680919647\n",
      "[6,    25] loss: 0.135 accuracy: 0.5454545617103577\n",
      "[7,    25] loss: 0.141 accuracy: 0.5909090638160706\n",
      "[8,    25] loss: 0.139 accuracy: 0.3636363744735718\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "outputs = None\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "training_accs = []\n",
    "validation_accs = []\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "    ##training\n",
    "    # running_loss = 0.0\n",
    "    model.train()\n",
    "    i = 0\n",
    "    for inputs, labels in dataloaders['train']:\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        # print(\"load to device: input\")\n",
    "        inputs = inputs.to(device)\n",
    "        # print(inputs.size())\n",
    "        # print(\"load to device: labels\")\n",
    "        labels = labels.to(device)\n",
    "        # print(\"all loaded\")\n",
    "        # zero the parameter gradients\n",
    "        optimizer_ft.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        # print(\"inferred\")\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_ft.step()\n",
    "        \n",
    "        # print statistics\n",
    "        # running_loss += loss.item()\n",
    "        training_losses.append(loss.item())\n",
    "        score = torch.mean((torch.Tensor.argmax(outputs,axis = 1)==labels).type(torch.FloatTensor))\n",
    "        training_accs.append(score)\n",
    "        i += 1\n",
    "        \n",
    "    # ##validation   \n",
    "    # model.eval()   \n",
    "    # for inputs, labels in dataloaders['val']:\n",
    "    #     inputs = inputs.to(device)\n",
    "    #     labels = labels.to(device)\n",
    "    #     # Forward Pass\n",
    "    #     outputs = model(inputs)\n",
    "    #     #statistics\n",
    "    #     #loss\n",
    "    #     validation_loss = criterion(outputs, labels)\n",
    "    #     validation_losses.append(validation_loss.item())\n",
    "    #     #accuracy\n",
    "    #     validation_accs.append(torch.mean((torch.Tensor.argmax(outputs,axis = 1)==labels).type(torch.FloatTensor)))\n",
    "        \n",
    "    if epoch % 1 == 0:    # print every 2000 mini-batches\n",
    "        print(f'[{epoch + 1}, {i + 1:5d}] loss: {loss.item() / 10:.3f} accuracy: {score}')\n",
    "        # running_loss = 0.0\n",
    "    exp_lr_scheduler.step()\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4zd7P8VDIgJ",
    "outputId": "31c731c0-e561-4d08-f982-0b4b811f29bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39.65176098, 47.01226751, 31.89552829, 38.14800158, 32.44954491,\n",
       "       10.84289672])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr = np.array([501,594,403,482,410,137])\n",
    "200*arr/np.sum(arr)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "iw [~/.conda/envs/iw/]",
   "language": "python",
   "name": "conda_iw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
